{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d97bf34",
   "metadata": {},
   "source": [
    "In this workspace, you'll scrape the novel Moby Dick from the website Project Gutenberg (which contains a large corpus of books) using the Python requests package. You'll extract words from this web data using BeautifulSoup before analyzing the distribution of words using the Natural Language ToolKit (nltk) and Counter.\n",
    "\n",
    "The Data Science pipeline you'll build in this workspace can be used to visualize the word frequency distributions of any novel you can find on Project Gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6f1853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shonakamura/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "\n",
      "<!DOCTYPE html\n",
      "   PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n",
      "   \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\" >\n",
      "\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
      "  <head>\n",
      "    <title>\n",
      "      Moby Dick; Or the Whale, by Herman Melville\n",
      "    </title>\n",
      "    <style type=\"text/css\" xml:space=\"preserve\">\n",
      "\n",
      "    body { background:#faebd0; color:black; margin-left:15%; margin-right:15%; text-align:justify }\n",
      "    P { text-indent: 1em; margin-top: .25em; margin-bottom: .25em; }\n",
      "    H1,H2,H3,H4,H5,H6 { text-align: center; margin-left: 15%; margin-right: 15%; }\n",
      "    hr  { width: 50%; text-align: center;}\n",
      "    .foot { margin-left: 20%; margin-right: 20%; text-align: justify; text-indent: -3em; font-size: 90%; }\n",
      "    blockquote {font-size: 100%; margin-left: 0%; margin-right: 0%;}\n",
      "    .mynote    {background-color: #DDE; color: #000; padding: .5em; margin-left: 10%; margin-right: 10%; font-family: sans-serif; font-size: 95%;}\n",
      "    .toc       { margin-left: 10%; margin-bottom: .75em;}\n",
      "    .toc2      { margin-left: 20%;}\n",
      "    div.fig    { display:block; margin:0 auto; text-align:center; }\n",
      "    div.middle { margin-left: 20%; margin-right: 20%; text-align: justify; }\n",
      "    .figleft   {float: left; margin-left: 0%; margin-right: 1%;}\n",
      "    .figright  {float: right; margin-right: 0%; margin-left: 1%;}\n",
      "    .pagenum   {display:inline; font-size: 70%; font-style:normal;\n",
      "               margin: 0; padding: 0; position: absolute; right: 1%;\n",
      "               text-align: right;}\n",
      "    pre        { font-family: times new roman; font-size: 100%; margin-left: 10%;}\n",
      "\n",
      "    table      {margin-left: 10%;}\n",
      "\n",
      "a:link {color:blue;\n",
      "\t\ttext-decoration:none}\n",
      "link {color:blue;\n",
      "\t\ttext-decoration:none}\n",
      "a:visited {color:blue;\n",
      "\t\ttext-decoration:none}\n",
      "a:hover {color:red}\n",
      "\n",
      "</style>\n",
      "  </head>\n",
      "  <body>\n",
      "<pre xml:space=\"preserve\">\n",
      "\n",
      "The Project Gutenberg EBook of Moby Dick; or The Whale, by Herman Melville\n",
      "\n",
      "This eBook is for the use of anyone anywh\n",
      "['moby', 'dick', 'or', 'the', 'whale', 'by', 'herman', 'melville']\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves']\n",
      "['moby', 'dick', 'whale', 'herman', 'melville']\n",
      "[('whale', 1246), ('one', 925), ('like', 647), ('upon', 568), ('man', 527), ('ship', 519), ('ahab', 517), ('ye', 473), ('sea', 455), ('old', 452)]\n"
     ]
    }
   ],
   "source": [
    "# Import and download packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from collections import Counter\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Request and encode the text\n",
    "r = requests.get('https://s3.amazonaws.com/assets.datacamp.com/production/project_147/datasets/2701-h.htm')\n",
    "r.encoding = 'utf-8'\n",
    "\n",
    "# Extract the text\n",
    "html = r.text\n",
    "print(html[:2000])\n",
    "\n",
    "# Create a BeautifulSoup object and get the text\n",
    "html_soup = BeautifulSoup(html, 'html.parser')\n",
    "moby_text = html_soup.get_text()\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n",
    "tokens = tokenizer.tokenize(moby_text)\n",
    "\n",
    "# Convert words to lowercase\n",
    "words = [word.lower() for word in tokens]\n",
    "print(words[:8])\n",
    "\n",
    "# Load in stop words\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "print(stop_words[:8])\n",
    "\n",
    "# Remove stop words from the text\n",
    "words_no_stop = [word for word in words if word not in stop_words]\n",
    "print(words_no_stop[:5])\n",
    "\n",
    "# Count the frequency of words\n",
    "count = Counter(words_no_stop)\n",
    "top_ten = count.most_common(10)\n",
    "print(top_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c0ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
